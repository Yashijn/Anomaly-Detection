{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each stock is from 2017 to current because only that much data is available on moneycontrol. Then removing all the news of the same date and consecutive dates because we can't measure the sentiment if more tha 1 news occur at the same time. Then we take difference of opening price of news date and the closing price of next date to find effect of news. Scale it from -5 to 5 for each stock this gives us the sentiment of news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_url = 'https://www.moneycontrol.com/'\n",
    "df2 = pd.read_csv('Top_Companies - India.csv')\n",
    "\n",
    "for x in range(0,df2.shape[0]):\n",
    "    if (1): \n",
    "        z=0\n",
    "        name = df2['Name'][x]\n",
    "        site = df2['site'][x]\n",
    "        tickers = df2['Tickers'][x]\n",
    "        print(name)\n",
    "        \n",
    "        df1 = yf.download(str(tickers)+\".NS\", start=\"2017-01-01\", end=\"2021-05-20\",group_by=\"ticker\") \n",
    "        df1.reset_index(inplace=True)\n",
    "        \n",
    "        List_of_links=[]\n",
    "        all_news = []\n",
    "        all_headlines = []\n",
    "        dates1 = []\n",
    "        \n",
    "        for i in range(2017,2022):\n",
    "            for j in range(1,100):\n",
    "                \n",
    "                dates2=[]\n",
    "                sub_links1=[]\n",
    "                \n",
    "                html = requests.get('https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id='+ str(site)+ '&scat=&pageno='+str(j)+'&next=0&durationType=Y&Year='+str(i)+'&duration=1&news_type=')\n",
    "                soup = BeautifulSoup(html.text,'html.parser')\n",
    "                sub_links = soup.find_all('a', class_='arial11_summ')\n",
    "                if not sub_links:\n",
    "                    break;\n",
    "                dates = soup.find_all('p', class_='PT3 a_10dgry')\n",
    "                dates = str(dates)\n",
    "                dates = re.findall('[0-9o/]{2}[\\s][A-Z]{1}[a-z]{2}[\\s][0-9O/]{4}[\\s]', dates)\n",
    "                dates = [x[:-1] for x in dates]\n",
    "                for m in range(len(dates)):\n",
    "                    date = dates[m].split(\" \")\n",
    "                    month = {'Jan':'01','Feb':'02','Mar':'03','Apr':'04','May':'05','Jun':'06','Jul':'07','Aug':'08',\n",
    "                             'Sep':'09','Oct':'10','Nov':'11','Dec':'12' }\n",
    "                    date[1] = month[date[1]]\n",
    "                    date.reverse()\n",
    "                    date = '-'.join(date)\n",
    "                    date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "                    dates2.append(date)\n",
    "                for k in range(len(dates2)):\n",
    "                    i=0\n",
    "                    for l in range(len(dates2)):\n",
    "                        if dates2[l] == dates2[k] or (dates2[l] - dates2[k]).days == 1:\n",
    "                            i=i+1\n",
    "                    if i==1:\n",
    "                        dates1.append(dates2[k])\n",
    "                        try:\n",
    "                            sub_links1.append(sub_links[k])\n",
    "                        except:\n",
    "                            z=1\n",
    "                            break\n",
    "                if z==1:\n",
    "                    break\n",
    "                print(dates1)\n",
    "                for links in sub_links1:\n",
    "                    sp = BeautifulSoup(str(links),'html.parser')  \n",
    "                    tag = sp.a\n",
    "                    category_links = Base_url + tag[\"href\"]\n",
    "                    List_of_links.append(category_links)\n",
    "                    time.sleep(3)\n",
    "\n",
    "    for links in List_of_links:\n",
    "        html = requests.get(links)\n",
    "        soup = BeautifulSoup(html.text,'html.parser')\n",
    "        Headlines = soup.find_all('title')\n",
    "        Headlines = str(Headlines)\n",
    "        Headlines = Headlines.strip(\"[<title>\")\n",
    "        Headlines = Headlines.strip(\"/title>]\")\n",
    "        Headlines = Headlines[ : -1]\n",
    "        all_headlines.append(Headlines)\n",
    "        if soup.find('div',{'class':'arti-flow'}):\n",
    "            news_text = soup.find('div',{'class':'arti-flow'})\n",
    "        else:\n",
    "            continue\n",
    "        for x in news_text.find_all(\"script\"):\n",
    "            x.decompose()\n",
    "        for y in news_text.find_all('style'):\n",
    "            y.decompose()\n",
    "        try:\n",
    "            news_text.find_all('a')[-1].decompose()\n",
    "        except:\n",
    "            all_news.append(Headlines)\n",
    "            continue\n",
    "        news = news_text.text\n",
    "        news = news[news.find('More'):]\n",
    "        all_news.append(news)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df = pd.DataFrame(list(zip(dates1, all_headlines, all_news)), columns =['Date', 'Headlines', 'News'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    days1 = timedelta(1)\n",
    "    days2 = timedelta(2)\n",
    "    days3 = timedelta(3)\n",
    "\n",
    "    Open = []\n",
    "    Close = []\n",
    "    for i in range(len(df)):\n",
    "        if df['Date'][i].weekday() == 5: \n",
    "            if df1[df1['Date'] == df['Date'][i]-days1]['Open'].empty == False:\n",
    "                Open.append(df1[df1['Date'] == df['Date'][i]-days1]['Open'].values[0])\n",
    "            else:\n",
    "                Open.append(0)\n",
    "        elif df['Date'][i].weekday() == 6:        \n",
    "            if df1[df1['Date'] == df['Date'][i]-days2]['Open'].empty == False:\n",
    "                Open.append(df1[df1['Date'] == df['Date'][i]-days2]['Open'].values[0])\n",
    "            else:\n",
    "                Open.append(0)\n",
    "        else:\n",
    "            if df1[df1['Date'] == df['Date'][i]]['Open'].empty == False:\n",
    "                Open.append(df1[df1['Date'] == df['Date'][i]]['Open'].values[0])\n",
    "            else:\n",
    "                Open.append(0)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df['Date'][i].weekday() == 4: \n",
    "            if df1[df1['Date'] == df['Date'][i] + days3]['Close'].empty == False:\n",
    "                Close.append(df1[df1['Date'] == df['Date'][i] + days3]['Close'].values[0])\n",
    "            else:\n",
    "                Close.append(0)\n",
    "        elif df['Date'][i].weekday() == 5:\n",
    "            if df1[df1['Date'] == df['Date'][i] + days2]['Close'].empty == False:\n",
    "                Close.append(df1[df1['Date'] == df['Date'][i] + days2]['Close'].values[0])\n",
    "            else:\n",
    "                Close.append(0)\n",
    "        else:\n",
    "            if df1[df1['Date'] == df['Date'][i] + days1]['Close'].empty == False:\n",
    "                Close.append(df1[df1['Date'] == df['Date'][i] + days1]['Close'].values[0])\n",
    "            else:\n",
    "                Close.append(0)\n",
    "        \n",
    "    df['Open'] = Open\n",
    "    df['Close'] = Close\n",
    "\n",
    "    for i in range(df.shape[0]):    \n",
    "        if pd.isnull(df['Close'][i]) == True or pd.isnull(df['Open'][i]) == True:\n",
    "            df = df.drop(i)\n",
    "            i=i+1    \n",
    "\n",
    "    df['Diff'] = df['Close'] - df['Open']\n",
    "    try:\n",
    "        if min(df['Diff']) < 0 and max(df['Diff']) > 0:\n",
    "            print('Proceed')\n",
    "        else:\n",
    "            print('Check if all positive and negative labels and redefine process')\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    diff1 = abs(min(df['Diff'])/5)\n",
    "    diff2 = max(df['Diff'])/5\n",
    "    l1=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        if df['Diff'][i] < (min(df['Diff']) + diff1):\n",
    "            l1.append(-5)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ diff1) and df['Diff'][i] < (min(df['Diff'])+ 2*diff1):\n",
    "            l1.append(-4)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ 2*diff1) and df['Diff'][i] < (min(df['Diff'])+ 3*diff1):\n",
    "            l1.append(-3)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ 3*diff1) and df['Diff'][i] < (min(df['Diff'])+ 4*diff1):\n",
    "            l1.append(-2)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ 4*diff1) and df['Diff'][i] < 0:\n",
    "            l1.append(-1)\n",
    "        if df['Diff'][i] == 0:\n",
    "            l1.append(0)\n",
    "        if df['Diff'][i] < diff2 and df['Diff'][i] > 0:\n",
    "            l1.append(1)\n",
    "        if df['Diff'][i] >= diff2 and df['Diff'][i] < 2*diff2:\n",
    "            l1.append(2)\n",
    "        if df['Diff'][i] >= 2*diff2 and df['Diff'][i] < 3*diff2:\n",
    "            l1.append(3)\n",
    "        if df['Diff'][i] >= 3*diff2 and df['Diff'][i] < 4*diff2:\n",
    "            l1.append(4)\n",
    "        if df['Diff'][i] >= 4*diff2 and df['Diff'][i] <= max(df['Diff']):\n",
    "            l1.append(5)\n",
    "    try:\n",
    "        df['sentiment'] = l1\n",
    "        df.to_csv(str(name)+'.csv')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have appended 0 where opening and closing price is not available. But this will affect our difference and sentiments of the dataset so I will remove all such values and calculate the sentiment again. Also a little deviation of difference of 0 from both sides considered as 5 sentiment news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('Dataset'):\n",
    "    filename1 = os.path.join('Dataset', filename)\n",
    "    df = pd.read_csv(str(filename1))\n",
    "    try:\n",
    "        df= df[df['Close'] != 0]\n",
    "    except:\n",
    "        continue\n",
    "    df= df[df['Open'] != 0]\n",
    "    df['Diff'] = df['Close'] - df['Open']\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    diff1 = abs(min(df['Diff'])/5)\n",
    "    diff2 = max(df['Diff'])/5\n",
    "    l1=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        if df['Diff'][i] < (min(df['Diff']) + diff1):\n",
    "            l1.append(-4)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ diff1) and df['Diff'][i] < (min(df['Diff'])+ 2*diff1):\n",
    "            l1.append(-3)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ 2*diff1) and df['Diff'][i] < (min(df['Diff'])+ 3*diff1):\n",
    "            l1.append(-2)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ 3*diff1) and df['Diff'][i] < (min(df['Diff'])+ 4*diff1):\n",
    "            l1.append(-1)\n",
    "        if df['Diff'][i] >= (min(df['Diff'])+ 4*diff1) and df['Diff'][i] < 0:\n",
    "            l1.append(0)\n",
    "        if df['Diff'][i] == 0:\n",
    "            l1.append(0)\n",
    "        if df['Diff'][i] < diff2 and df['Diff'][i] > 0:\n",
    "            l1.append(0)\n",
    "        if df['Diff'][i] >= diff2 and df['Diff'][i] < 2*diff2:\n",
    "            l1.append(1)\n",
    "        if df['Diff'][i] >= 2*diff2 and df['Diff'][i] < 3*diff2:\n",
    "            l1.append(2)\n",
    "        if df['Diff'][i] >= 3*diff2 and df['Diff'][i] < 4*diff2:\n",
    "            l1.append(3)\n",
    "        if df['Diff'][i] >= 4*diff2 and df['Diff'][i] <= max(df['Diff']):\n",
    "            l1.append(4)\n",
    "    \n",
    "    selected_columns = df[[\"Date\",\"Headlines\",\"News\",\"sentiment\"]]\n",
    "    df = selected_columns.copy()\n",
    "    df['sentiment'] = l1\n",
    "    df.to_csv(str(filename1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8713\n"
     ]
    }
   ],
   "source": [
    "global i\n",
    "i=0\n",
    "for filename in os.listdir('Dataset'):\n",
    "    if filename.endswith(\".csv\"): \n",
    "        filename1 = os.path.join('Dataset', filename)\n",
    "        df = pd.read_csv(str(filename1))\n",
    "        i = i+df.shape[0]\n",
    "        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8713"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for filename in os.listdir('Dataset'):\n",
    "    filename1 = os.path.join('Dataset', filename)\n",
    "    df = df.append(pd.read_csv(str(filename1)))\n",
    "    \n",
    "df.to_csv('Stocks_Dataset.csv')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
